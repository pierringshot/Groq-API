# Repository Blurb (Short Description) âœ¨ğŸ”§ğŸ“˜

**EN:** Standardsâ€‘conformant Groq client implementing perâ€‘key tokenâ€‘bucket rate limiting, firstâ€‘class `Retryâ€‘After` semantics, exponential backoff with decorrelated jitter, persistent JSONâ€‘backed caching, and bounded concurrency â€” with no ancillary logging dependencies. âœ¨ğŸ”§ğŸ“˜

**AZ:** Groq Ã¼Ã§Ã¼n siyasÉ™tÉ™ uyÄŸun mÃ¼ÅŸtÉ™ri: aÃ§arâ€‘baÅŸÄ±na token bucket, `Retryâ€‘After` hÃ¶rmÉ™ti, eksponensial backoff, JSON keÅŸ vÉ™ paralel icra nÉ™zarÉ™ti â€” É™lavÉ™ logging asÄ±lÄ±lÄ±ÄŸÄ± yoxdur. âœ¨ğŸ”§ğŸ“˜

---

# README.md â€” Compliant Groq Client (Rateâ€‘limitâ€‘safe Kit) âœ¨ğŸ”§ğŸ“˜

A resilient, **termsâ€‘compliant** Groq API client that gracefully handles rate limits and network hiccups. It honors `HTTP 429` and `Retryâ€‘After`, applies **perâ€‘key tokenâ€‘bucket** throttling, uses **exponential backoff with jitter**, and avoids duplicate calls via a lightweight **JSON cache**. Designed to be dropâ€‘in and CIâ€‘friendly with **no external logging dependencies**. âœ¨ğŸ”§ğŸ“˜

> Code lives in `groq_client_compliant.py` and includes inline comments plus selfâ€‘tests. âœ¨ğŸ”§ğŸ“˜

## Features âœ¨ğŸ”§ğŸ“˜

* **Policyâ€‘compliant throttling:** Honors `Retryâ€‘After` (seconds or HTTPâ€‘date).
* **Perâ€‘key token buckets:** Convert RPM â†’ perâ€‘second refill; fair roundâ€‘robin across keys.
* **Exponential backoff + jitter:** Gentle retries for 5xx/network errors.
* **Local JSON cache:** Deduplicates identical requests (default TTL: 6h).
* **Concurrency control:** Global semaphore to prevent overload.
* **Daily token budget (optional):** Soft cap on estimated token usage.
* **Zero extra logging deps:** ANSIâ€‘colored logs without `rich/pygments`.

## Requirements âœ¨ğŸ”§ğŸ“˜

* Python **3.9+**
* Package: `httpx` (install below)

```bash
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install httpx>=0.27
```

## Quick Start âœ¨ğŸ”§ğŸ“˜

Export a key and run one of the input modes. âœ¨ğŸ”§ğŸ“˜

```bash
# Single key
export GROQ_API_KEY='gsk_...'
# Multiple keys (same org/account, policyâ€‘compliant)
export GROQ_API_KEYS='gsk_key1,gsk_key2'
```

### Input options (choose one) âœ¨ğŸ”§ğŸ“˜

* **Positional text:**

  ```bash
  python groq_client_compliant.py "What is red teaming?"
  ```
* **From file:**

  ```bash
  echo "Explain DDoS indicators." > prompt.txt
  python groq_client_compliant.py --prompt-file prompt.txt
  ```
* **From STDIN (pipe):**

  ```bash
  echo "Nginx 4xx spike causes?" | python groq_client_compliant.py --stdin
  ```
* **Fallback text (no other input):**

  ```bash
  python groq_client_compliant.py --default-prompt "Summarize incident triage steps."
  ```
* **Selfâ€‘tests only:**

  ```bash
  python groq_client_compliant.py --self-test
  ```

### Common flags âœ¨ğŸ”§ğŸ“˜

```bash
--model llama3-8b-8192         # API model name
--rpm 30                        # Perâ€‘key RPM for token bucket
--concurrency 8                 # Max parallel inâ€‘flight calls
--budget 150000                 # Optional daily token budget (soft)
--cache .groq_cache.json        # Cache file path
```

## Programmatic Usage âœ¨ğŸ”§ğŸ“˜

```python
import asyncio
from pathlib import Path
from groq_client_compliant import GroqClient

async def main():
    keys = ["gsk_...1", "gsk_...2"]  # authorized keys
    client = GroqClient(keys=keys, rpm_per_key=30, max_concurrency=8, cache_path=Path('.groq_cache.json'))
    try:
        messages = [{"role": "user", "content": "Give a oneâ€‘liner on DDoS."}]
        text = await client.chat(messages, model="llama3-8b-8192")
        print(text)
    finally:
        await client.aclose()

asyncio.run(main())
```

## How It Works âœ¨ğŸ”§ğŸ“˜

* **KeyManager:** Roundâ€‘robin allocator across keys; applies perâ€‘key token bucket and temporary **cooldowns** when servers return `429` with `Retryâ€‘After`.
* **TokenBucket:** Standard leaky/token bucket where tokens refill by time and are required per request.
* **Backoff:** For 5xx/network errors, wait using exponential backoff with jitter to avoid synchronized retries.
* **Cache:** SHAâ€‘256 of request payload â†’ value, written to a small JSON file; TTL prunes stale entries on startup.
* **Concurrency:** Global semaphore ensures at most *N* concurrent requests.

## Logging âœ¨ğŸ”§ğŸ“˜

* Uses standard `logging` with a minimal ANSI color formatter.
* Colors appear when attached to a TTY; otherwise log lines are plain text.

## CLI Behavior âœ¨ğŸ”§ğŸ“˜

* If **no input** is provided, the tool **runs selfâ€‘tests** by default and exits successfully.
* Provide input via positional arg, `--prompt-file`, `--stdin`, or `--default-prompt`.

## Environment Variables âœ¨ğŸ”§ğŸ“˜

* `GROQ_API_KEY` â€” single key (alternative to `GROQ_API_KEYS`).
* `GROQ_API_KEYS` â€” commaâ€‘separated keys (policyâ€‘compliant use only).

> Keys must be authorized and used within provider policies. This client is built to **respect** limits, not circumvent them. âœ¨ğŸ”§ğŸ“˜

## Testing âœ¨ğŸ”§ğŸ“˜

Run builtâ€‘in offline tests: âœ¨ğŸ”§ğŸ“˜

```bash
python groq_client_compliant.py --self-test
```

Tests cover: âœ¨ğŸ”§ğŸ“˜

* `Retryâ€‘After` parsing (seconds & HTTPâ€‘date)
* Exponential backoff jitter
* Cache read/write
* Token bucket behavior
* Prompt resolution precedence

## Security & Compliance âœ¨ğŸ”§ğŸ“˜

* **Do not** use unapproved keys or identities.
* This client **does not** proxy/rotate to evade limits; it obeys provider signals.
* Rotate credentials if you ever suspect leakage; **never commit `.env`** files.

## Limitations âœ¨ğŸ”§ğŸ“˜

* Token counting is an estimate unless the API returns exact usage.
* Cache TTL is static (6h) and configured in code.
* Only the chat completions endpoint is implemented by default.

## Roadmap (optional) âœ¨ğŸ”§ğŸ“˜

* Configurable cache TTL via CLI
* Pluggable storage (SQLite/Redis) for cache
* Streaming responses and partial retry
* Metrics hooks (Prometheus/OpenTelemetry)

## License âœ¨ğŸ”§ğŸ“˜

Choose a license that fits your project (e.g., MIT). Add a `LICENSE` file at repo root. âœ¨ğŸ”§ğŸ“˜

## Contributing âœ¨ğŸ”§ğŸ“˜

1. Fork â†’ feature branch â†’ PR.
2. Keep changes small and covered by tests (`--self-test` can be extended).
3. Follow conventional commit messages (e.g., `feat(client): add streaming`).
